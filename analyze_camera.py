"""
Script d'analyse des mouvements de cam√©ra pour la vid√©o d'√©checs
D√©tecte les zooms et d√©zooms pour reproduire les effets dans Godot
"""

import cv2
import numpy as np
import json
import sys
from pathlib import Path

class CameraAnalyzer:
    def __init__(self, video_path):
        self.video_path = video_path
        self.cap = cv2.VideoCapture(video_path)
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.duration = self.total_frames / self.fps
        
        self.camera_movements = []
        self.prev_frame = None
        
    def analyze_camera_zoom(self, frame, prev_frame, frame_num, timestamp):
        """Analyse le zoom de la cam√©ra en comparant les frames"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
        
        # D√©tection de caract√©ristiques pour suivre le mouvement
        # Utilise ORB (Oriented FAST and Rotated BRIEF)
        orb = cv2.ORB_create(nfeatures=100)
        
        # D√©tecter les points cl√©s
        kp1, des1 = orb.detectAndCompute(prev_gray, None)
        kp2, des2 = orb.detectAndCompute(gray, None)
        
        if des1 is not None and des2 is not None and len(des1) > 10 and len(des2) > 10:
            # Matcher les caract√©ristiques
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
            matches = bf.match(des1, des2)
            
            if len(matches) > 10:
                # Calculer les distances entre points match√©s
                distances = []
                for match in matches:
                    pt1 = kp1[match.queryIdx].pt
                    pt2 = kp2[match.trainIdx].pt
                    dist = np.sqrt((pt2[0] - pt1[0])**2 + (pt2[1] - pt1[1])**2)
                    distances.append(dist)
                
                avg_distance = np.mean(distances)
                
                # Flux optique pour d√©tecter le mouvement
                flow = cv2.calcOpticalFlowFarneback(
                    prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0
                )
                
                # Calculer la magnitude et l'angle du flux
                mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])
                avg_mag = np.mean(mag)
                
                # Analyser le pattern de mouvement
                # Zoom in : les points s'√©loignent du centre
                # Zoom out : les points se rapprochent du centre
                
                center_x, center_y = self.width // 2, self.height // 2
                
                # Calculer le mouvement radial
                flow_x = flow[..., 0]
                flow_y = flow[..., 1]
                
                # Cr√©er une grille de coordonn√©es
                y_coords, x_coords = np.mgrid[0:self.height, 0:self.width]
                
                # Vecteurs du centre vers chaque point
                to_center_x = x_coords - center_x
                to_center_y = y_coords - center_y
                
                # Normaliser
                distances_from_center = np.sqrt(to_center_x**2 + to_center_y**2)
                distances_from_center[distances_from_center == 0] = 1  # √âviter division par z√©ro
                
                to_center_x_norm = to_center_x / distances_from_center
                to_center_y_norm = to_center_y / distances_from_center
                
                # Produit scalaire entre flux et direction radiale
                radial_flow = flow_x * to_center_x_norm + flow_y * to_center_y_norm
                avg_radial_flow = np.mean(radial_flow)
                
                # D√©terminer le type de mouvement
                movement_type = "static"
                zoom_factor = 1.0
                
                if avg_mag > 1.5:  # Mouvement significatif
                    if avg_radial_flow > 0.5:
                        # Flux s'√©loigne du centre = ZOOM IN
                        movement_type = "zoom_in"
                        zoom_factor = 1.0 + (avg_mag / 20.0)
                    elif avg_radial_flow < -0.5:
                        # Flux se rapproche du centre = ZOOM OUT
                        movement_type = "zoom_out"
                        zoom_factor = 1.0 - (avg_mag / 20.0)
                    else:
                        # Mouvement panoramique
                        movement_type = "pan"
                        zoom_factor = 1.0
                
                if movement_type != "static":
                    return {
                        "frame": int(frame_num),
                        "timestamp": float(round(timestamp, 3)),
                        "type": str(movement_type),
                        "magnitude": float(round(avg_mag, 3)),
                        "radial_flow": float(round(avg_radial_flow, 3)),
                        "zoom_factor": float(round(zoom_factor, 3)),
                        "feature_matches": int(len(matches))
                    }
        
        return None
    
    def analyze(self):
        """Lance l'analyse de la vid√©o"""
        print(f"üé¨ Analyse de la vid√©o : {self.video_path}")
        print(f"üìä R√©solution : {self.width}x{self.height}")
        print(f"‚è±Ô∏è  Dur√©e : {self.duration:.2f}s ({self.total_frames} frames @ {self.fps} FPS)")
        print()
        
        frame_count = 0
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            timestamp = frame_count / self.fps
            
            # Analyser le mouvement de cam√©ra
            if self.prev_frame is not None and frame_count % 2 == 0:  # Analyser toutes les 2 frames
                camera_move = self.analyze_camera_zoom(frame, self.prev_frame, frame_count, timestamp)
                if camera_move:
                    self.camera_movements.append(camera_move)
            
            self.prev_frame = frame.copy()
            
            # Afficher la progression
            if frame_count % 30 == 0:
                progress = (frame_count / self.total_frames) * 100
                print(f"Progression : {progress:.1f}%", end='\r')
            
            frame_count += 1
        
        self.cap.release()
        print(f"\n‚úÖ Analyse termin√©e !")
        
        # Regrouper les mouvements cons√©cutifs
        self.consolidate_movements()
        
        # G√©n√©rer le rapport
        self.generate_report()
    
    def consolidate_movements(self):
        """Regroupe les mouvements cons√©cutifs similaires"""
        if not self.camera_movements:
            return
        
        consolidated = []
        current_move = self.camera_movements[0].copy()
        current_move['start_time'] = current_move['timestamp']
        current_move['end_time'] = current_move['timestamp']
        current_move['duration'] = 0
        
        for i in range(1, len(self.camera_movements)):
            move = self.camera_movements[i]
            
            # Si m√™me type et proche dans le temps (< 0.5s)
            if (move['type'] == current_move['type'] and 
                move['timestamp'] - current_move['end_time'] < 0.5):
                # √âtendre le mouvement actuel
                current_move['end_time'] = move['timestamp']
                current_move['magnitude'] = max(current_move['magnitude'], move['magnitude'])
                current_move['zoom_factor'] = move['zoom_factor']
            else:
                # Sauvegarder le mouvement actuel
                current_move['duration'] = current_move['end_time'] - current_move['start_time']
                consolidated.append(current_move)
                
                # Commencer un nouveau mouvement
                current_move = move.copy()
                current_move['start_time'] = move['timestamp']
                current_move['end_time'] = move['timestamp']
                current_move['duration'] = 0
        
        # Ajouter le dernier mouvement
        current_move['duration'] = current_move['end_time'] - current_move['start_time']
        consolidated.append(current_move)
        
        self.consolidated_movements = consolidated
    
    def generate_report(self):
        """G√©n√®re le rapport d'analyse"""
        report = {
            "metadata": {
                "video_path": self.video_path,
                "duration": self.duration,
                "fps": self.fps,
                "resolution": f"{self.width}x{self.height}",
                "total_frames": self.total_frames
            },
            "raw_movements": self.camera_movements,
            "consolidated_movements": self.consolidated_movements if hasattr(self, 'consolidated_movements') else []
        }
        
        # Sauvegarder en JSON
        output_file = Path("camera_analysis.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Rapport sauvegard√© : {output_file}")
        
        # Afficher le r√©sum√©
        print("\n" + "="*70)
        print("üìä R√âSUM√â DE L'ANALYSE DES MOUVEMENTS DE CAM√âRA")
        print("="*70)
        print(f"üé• Mouvements d√©tect√©s : {len(self.camera_movements)}")
        
        if hasattr(self, 'consolidated_movements'):
            print(f"üìå Mouvements consolid√©s : {len(self.consolidated_movements)}\n")
            
            print("üîç MOUVEMENTS PRINCIPAUX :")
            for i, move in enumerate(self.consolidated_movements, 1):
                print(f"\n{i}. {move['type'].upper().replace('_', ' ')}")
                print(f"   ‚è±Ô∏è  D√©but : {move['start_time']:.2f}s")
                print(f"   ‚è±Ô∏è  Fin : {move['end_time']:.2f}s")
                print(f"   ‚åõ Dur√©e : {move['duration']:.2f}s")
                print(f"   üí™ Intensit√© : {move['magnitude']:.2f}")
                if 'zoom' in move['type']:
                    print(f"   üîé Facteur de zoom : {move['zoom_factor']:.3f}")
        
        print("\n" + "="*70)
        
        # G√©n√©rer le guide d'impl√©mentation Godot
        self.generate_godot_guide()
    
    def generate_godot_guide(self):
        """G√©n√®re un guide pour impl√©menter ces mouvements dans Godot"""
        guide = """
# üéÆ GUIDE D'IMPL√âMENTATION GODOT - Mouvements de Cam√©ra

## üìã R√©sum√© des mouvements d√©tect√©s

"""
        
        if hasattr(self, 'consolidated_movements'):
            for i, move in enumerate(self.consolidated_movements, 1):
                guide += f"""
### Mouvement {i} : {move['type'].upper().replace('_', ' ')}
- **Timing** : {move['start_time']:.2f}s ‚Üí {move['end_time']:.2f}s (dur√©e: {move['duration']:.2f}s)
- **Intensit√©** : {move['magnitude']:.2f}
- **Facteur de zoom** : {move.get('zoom_factor', 1.0):.3f}
"""
        
        guide += """

## üé¨ Impl√©mentation dans Godot (GDScript)

### 1. Cr√©er un script CameraController.gd

```gdscript
extends Camera3D
class_name ChessCameraController

# Param√®tres de zoom
var zoom_speed: float = 2.0
var min_zoom: float = 5.0
var max_zoom: float = 20.0
var target_zoom: float = 10.0
var current_zoom: float = 10.0

# Param√®tres de mouvement
var camera_offset: Vector3 = Vector3(0, 10, 8)
var look_at_target: Vector3 = Vector3.ZERO

# Animations planifi√©es
var camera_animations: Array = []
var current_animation_index: int = 0
var animation_time: float = 0.0

func _ready():
    # Initialiser la position de la cam√©ra
    position = camera_offset
    look_at(look_at_target)
    
    # Charger les animations depuis l'analyse
    load_camera_animations()

func _process(delta):
    # Traiter l'animation en cours
    if current_animation_index < camera_animations.size():
        process_camera_animation(delta)
    
    # Interpolation douce du zoom
    current_zoom = lerp(current_zoom, target_zoom, delta * zoom_speed)
    
    # Appliquer le zoom (ajuster la distance)
    var zoom_offset = camera_offset.normalized() * current_zoom
    position = lerp(position, zoom_offset, delta * 5.0)

func process_camera_animation(delta):
    var anim = camera_animations[current_animation_index]
    animation_time += delta
    
    # V√©rifier si l'animation doit commencer
    if animation_time < anim.start_time:
        return
    
    # Calculer la progression de l'animation
    var duration = anim.end_time - anim.start_time
    var progress = (animation_time - anim.start_time) / duration
    
    if progress >= 1.0:
        # Animation termin√©e, passer √† la suivante
        current_animation_index += 1
        return
    
    # Appliquer l'animation selon le type
    match anim.type:
        "zoom_in":
            animate_zoom_in(progress, anim)
        "zoom_out":
            animate_zoom_out(progress, anim)
        "pan":
            animate_pan(progress, anim)

func animate_zoom_in(progress: float, anim: Dictionary):
    # Interpolation douce avec easing
    var eased_progress = ease(progress, -2.0)  # Ease out
    
    # Calculer le zoom cible
    var start_zoom = current_zoom
    var end_zoom = start_zoom / anim.zoom_factor
    
    target_zoom = lerp(start_zoom, end_zoom, eased_progress)

func animate_zoom_out(progress: float, anim: Dictionary):
    var eased_progress = ease(progress, 2.0)  # Ease in
    
    var start_zoom = current_zoom
    var end_zoom = start_zoom * (2.0 - anim.zoom_factor)
    
    target_zoom = lerp(start_zoom, end_zoom, eased_progress)

func animate_pan(progress: float, anim: Dictionary):
    # D√©placer la cam√©ra lat√©ralement
    var pan_amount = anim.magnitude * 0.1
    var pan_direction = Vector3(cos(animation_time), 0, sin(animation_time))
    
    position += pan_direction * pan_amount * 0.01

func load_camera_animations():
    # Charger les animations depuis l'analyse JSON
    # Pour l'instant, voici des exemples bas√©s sur l'analyse
    
"""
        
        # Ajouter les animations d√©tect√©es
        if hasattr(self, 'consolidated_movements'):
            guide += "    # Animations d√©tect√©es automatiquement :\n"
            for move in self.consolidated_movements:
                guide += f"""    camera_animations.append({{
        "type": "{move['type']}",
        "start_time": {move['start_time']:.2f},
        "end_time": {move['end_time']:.2f},
        "magnitude": {move['magnitude']:.2f},
        "zoom_factor": {move.get('zoom_factor', 1.0):.3f}
    }})
"""
        
        guide += """

### 2. Utilisation dans votre sc√®ne

```gdscript
# Dans votre script Board.gd ou Main.gd
extends Node3D

@onready var camera = $ChessCameraController

func _ready():
    # La cam√©ra va automatiquement jouer les animations planifi√©es
    pass

func trigger_move_animation(from_square: Vector2i, to_square: Vector2i):
    # Quand un coup est jou√©, d√©clencher le zoom sur l'action
    var world_pos = board_to_world(to_square)
    camera.zoom_to_position(world_pos, 1.5)  # Zoom pendant 1.5s

func board_to_world(square: Vector2i) -> Vector3:
    # Convertir coordonn√©es √©chiquier en position 3D
    var x = (square.x - 3.5) * 1.0
    var z = (square.y - 3.5) * 1.0
    return Vector3(x, 0, z)
```

### 3. Am√©lioration : Zoom dynamique sur l'action

```gdscript
# Ajouter cette fonction √† CameraController.gd

func zoom_to_position(target_pos: Vector3, duration: float = 1.0):
    # Cr√©er une animation de zoom vers une position sp√©cifique
    var tween = create_tween()
    
    # Calculer nouvelle position de cam√©ra
    var direction = (position - target_pos).normalized()
    var new_pos = target_pos + direction * 5.0  # 5 unit√©s de distance
    
    # Animer la position
    tween.tween_property(self, "position", new_pos, duration).set_trans(Tween.TRANS_CUBIC).set_ease(Tween.EASE_IN_OUT)
    
    # Animer le look_at
    tween.parallel().tween_method(
        func(p): look_at(target_pos),
        0.0, 1.0, duration
    )
    
    return tween

func zoom_on_piece_capture(captured_pos: Vector3):
    # Zoom rapide sur une pi√®ce captur√©e
    var tween = zoom_to_position(captured_pos, 0.5)
    
    # Apr√®s le zoom, revenir √† la vue normale
    await tween.finished
    await get_tree().create_timer(0.3).timeout
    
    reset_camera_view(0.8)

func reset_camera_view(duration: float = 1.0):
    # Retour √† la vue normale
    var tween = create_tween()
    tween.tween_property(self, "position", camera_offset, duration).set_trans(Tween.TRANS_CUBIC).set_ease(Tween.EASE_IN_OUT)
    tween.parallel().tween_method(
        func(p): look_at(look_at_target),
        0.0, 1.0, duration
    )
```

## üéØ Points cl√©s pour reproduire le style de la vid√©o

### 1. Timing des zooms
- **Zoom IN** : Lorsqu'un coup important est jou√© (capture, √©chec, mat)
- **Zoom OUT** : Pour montrer l'ensemble du plateau
- **Dur√©e typique** : 0.5s √† 2s par mouvement

### 2. Courbes d'easing recommand√©es
- **Zoom IN** : `EASE_OUT` (rapide au d√©but, ralentit √† la fin)
- **Zoom OUT** : `EASE_IN_OUT` (doux aux deux extr√©mit√©s)
- **Pan** : `LINEAR` ou `EASE_IN_OUT`

### 3. D√©clencheurs sugg√©r√©s
```gdscript
# Dans votre logique de jeu
func on_piece_moved(from: Vector2i, to: Vector2i, piece: ChessPiece):
    var move_data = analyze_move(from, to, piece)
    
    if move_data.is_capture:
        # Zoom sur la capture
        camera.zoom_to_position(board_to_world(to), 0.8)
    elif move_data.is_check:
        # Zoom sur le roi en √©chec
        camera.zoom_to_king(get_king_in_check(), 1.0)
    elif move_data.is_castling:
        # Zoom out pour voir le roque
        camera.zoom_out_view(1.2)
```

### 4. Effets additionnels (comme dans la vid√©o)
- **Shake de cam√©ra** lors de captures importantes
- **Rotation l√©g√®re** pour dynamiser les coups
- **Ralenti (slow-motion)** pour les moments critiques

```gdscript
func add_camera_shake(intensity: float = 0.1, duration: float = 0.3):
    var original_pos = position
    var shake_timer = 0.0
    
    while shake_timer < duration:
        var shake_offset = Vector3(
            randf_range(-intensity, intensity),
            randf_range(-intensity, intensity),
            randf_range(-intensity, intensity)
        )
        position = original_pos + shake_offset
        shake_timer += get_process_delta_time()
        await get_tree().process_frame
    
    position = original_pos
```

## üìä Statistiques de la vid√©o analys√©e
"""
        
        if hasattr(self, 'consolidated_movements'):
            zoom_in_count = sum(1 for m in self.consolidated_movements if m['type'] == 'zoom_in')
            zoom_out_count = sum(1 for m in self.consolidated_movements if m['type'] == 'zoom_out')
            pan_count = sum(1 for m in self.consolidated_movements if m['type'] == 'pan')
            
            guide += f"""
- **Total de mouvements** : {len(self.consolidated_movements)}
- **Zooms IN** : {zoom_in_count}
- **Zooms OUT** : {zoom_out_count}
- **Panoramiques** : {pan_count}
- **Dur√©e moyenne** : {np.mean([m['duration'] for m in self.consolidated_movements]):.2f}s
"""
        
        guide += "\n\n---\n‚ú® G√©n√©r√©e automatiquement par camera_analyzer.py\n"
        
        # Sauvegarder le guide
        guide_file = Path("GODOT_CAMERA_GUIDE.md")
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide)
        
        print(f"üìñ Guide Godot g√©n√©r√© : {guide_file}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("‚ùå Usage: python3 analyze_camera.py <video_path>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    
    if not Path(video_path).exists():
        print(f"‚ùå Vid√©o non trouv√©e : {video_path}")
        sys.exit(1)
    
    analyzer = CameraAnalyzer(video_path)
    analyzer.analyze()
